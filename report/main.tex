\documentclass[a4paper,12pt]{article}

% Packages
\usepackage{url}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{titlesec}  % For title formatting
\usepackage{booktabs}  % for professional tables
\usepackage{caption}  % better figure/table captions
\usepackage{subcaption}
\geometry{margin=1in}
\setstretch{1.5}
\setlength{\headheight}{14.49998pt}
\addtolength{\topmargin}{-2.49998pt}

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Google Cluster Analysis}
\fancyhead[R]{\thepage}

% Title Formatting
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}

% Cover Page
\title{
    \vspace{2cm}
    \includegraphics[width=0.5\textwidth]{logo_hkust2.png} \\
    \vspace{1cm}
    \textbf{\Huge Google Cluster Trace Analysis and Failure Prediction} \\
    \vspace{0.5cm}
    \large CSIT5970 Final Project Report \\
    \vspace{0.3cm}
    \large May 2025
}
\author{LI Zhicheng, WANG Ziling, YANG Zhuorui}
\date{}

\begin{document}

% Title Page
\maketitle
\thispagestyle{empty}
\newpage

% Table of Contents
% Start page numbering from the Table of Contents
\setcounter{page}{1}  % Start counting from 1
\tableofcontents
\newpage

\begin{abstract}
As large-scale cluster management systems become the backbone of cloud computing platforms, understanding workload behavior and scheduling dynamics has become increasingly critical. In this project, we conduct a comprehensive analysis of a real-world dataset derived from Google Borg traces. We preprocess semi-structured logs, extract key features such as resource requests and task runtime, and derive metrics like resource efficiency and queuing delay.

Through exploratory data analysis (EDA), we reveal patterns linking task failures to resource request sizes and scheduling classes. We further apply machine learning models---including Logistic Regression, Random Forest, and XGBoost---to predict task failures, achieving a ROC-AUC of 0.998 with XGBoost. Finally, we use clustering techniques to uncover structural differences among failed tasks.

Our findings suggest opportunities for improving scheduling fairness and resource utilization. The analysis pipeline is reproducible and offers valuable insights for optimizing cluster management strategies.
\end{abstract}

\section{Introduction}

Large-scale cluster computing systems such as Google's Borg, Kubernetes, and Apache Mesos form the backbone of modern cloud infrastructure. These systems orchestrate thousands of heterogeneous tasks across massive clusters while maintaining high availability and efficiency. Analyzing job traces from such systems provides critical insights into workload characteristics, scheduling behavior, and resource utilization patterns.

However, studying production-scale traces presents several challenges. First, the data is high-volume and semi-structured, with key features such as resource requests embedded in string-encoded dictionaries. Second, task behaviors are highly diverse, with failure events being rare but impactful. Third, many features—such as task priorities, scheduling class, and runtime—interact in non-trivial ways that affect both performance and robustness.

To address these issues, we conduct a comprehensive data analysis on a real-world cluster trace dataset derived from Google's Borg system. Our analysis aims to answer the following research questions:

\begin{itemize}
  \item How are resource requests related to task failure and efficiency?
  \item What are the characteristics of tasks with long queuing delays?
  \item Can we predict task failure using basic scheduling features?
  \item What patterns exist among failed tasks in terms of clustering?
\end{itemize}

We preprocess the raw trace data into a structured format and perform exploratory data analysis (EDA) to identify core behavioral trends. We then apply machine learning models—including logistic regression, random forest, and XGBoost—to predict task failures based on their attributes. Finally, we cluster failed tasks using KMeans to uncover behavioral subgroups.

Our study highlights inefficiencies in resource usage and scheduling fairness, and provides actionable insights for system operators and schedulers. The methods and results are reproducible via open-source notebooks and visualized with annotated charts.

\section{Related Work}

Understanding cluster workloads and scheduling behavior has been a long-standing area of interest in systems research. The release of anonymized traces from Google's Borg system~\cite{reiss2012heterogeneity} has enabled a wide range of empirical studies on data center dynamics, including resource usage modeling~\cite{wilkes2011more}, job co-location analysis~\cite{verma2015large}, and failure characterization~\cite{qin2017analyzing}.

Several works have explored resource allocation efficiency. Wilkes~\cite{wilkes2011more} discusses over-provisioning and underutilization issues in large-scale clusters. Subsequent studies~\cite{chen2019understanding, hindman2011mesos} extend this by linking task inefficiencies to scheduling classes and workload priorities.

Task failure prediction is another important topic. Researchers have proposed models using logistic regression, decision trees, and neural networks to forecast job failures~\cite{gupta2014failure, vishwanath2010characterizing}. These approaches often rely on features such as resource request size, priority level, and job duration, which aligns with our methodology.

Recent analyses on scheduling fairness and queuing behavior~\cite{sharma2011cutting, delgado2016job} also motivate our investigation of queuing delay distributions. Our project builds upon these foundations, offering an end-to-end empirical pipeline that combines statistical profiling, predictive modeling, and unsupervised clustering to better understand cluster workload behavior.

\section{Methodology and Experimental Setup}

This section outlines the overall methodology adopted in our analysis and describes the technical steps required to prepare, process, and analyze the large-scale Google cluster trace dataset.

\subsection{Data Preprocessing}

We begin by reading the raw CSV trace data, consisting of over 2 million task instances. To reduce memory pressure and improve processing efficiency, the data was first cleaned using a PySpark pipeline. Key fields such as \texttt{resource\_request}, \texttt{run\_duration}, \texttt{priority}, and \texttt{failed} were extracted and parsed using regular expressions. Tasks with missing or invalid fields were removed, and extreme values in \texttt{queueing\_delay}, \texttt{resource\_efficiency}, etc., were capped or filtered based on quantile thresholds. The cleaned data was stored in Parquet format to facilitate fast reloading.

\subsection{Exploratory Analysis Pipeline}

Exploratory Data Analysis (EDA) was conducted via Jupyter notebooks in multiple stages. We began by examining the relationship between resource request sizes and failure rates, followed by an investigation into queuing behavior across different scheduling classes and priorities. Additional analyses were conducted to explore runtime distributions and task efficiency extremes. All plots were generated using Seaborn and Matplotlib, and where necessary, sampled data (e.g., top 5\% or 10,000 records) was used to improve visualization clarity.

\subsection{Failure Prediction and Clustering Strategy}

For predictive modeling, we trained three classification models: Logistic Regression, Random Forest, and XGBoost. Each model was evaluated using accuracy, precision, recall, F1-score, and ROC AUC. The input features included task \texttt{priority}, \texttt{scheduling\_class}, \texttt{cpu\_request}, \texttt{mem\_request}, and normalized \texttt{run\_duration}. To mitigate class imbalance, class weights were adjusted, and stratified sampling was applied.

Additionally, we performed unsupervised clustering of failed tasks using KMeans to reveal distinct behavioral patterns. Clustering was based on the same features used in prediction, and results were visualized in 2D plots to show group separation based on runtime and priority.

\section{Results and Insights}

This section presents detailed findings from our analysis, based on the full Google Cluster workload dataset (over 240k tasks across 4k collections). Visualizations are organized by thematic focus, highlighting the interplay between scheduling behavior, failure risk, and resource efficiency.

\subsection{Resource Request Patterns and Failure Risk}

Most tasks request less than 0.1 CPUs and minimal memory. However, low resource request bins also exhibit higher task failure rates (Figure~\ref{fig:fail-vs-request}). This suggests lightweight tasks are more prone to failure, potentially due to tighter scheduling or lower redundancy.

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/02_task_failure_rate_vs_cpu_request_size.png}
    \caption{Failure vs. CPU Request}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/02_task_failure_rate_vs_mem_request_size.png}
    \caption{Failure vs. Memory Request}
  \end{subfigure}
  \caption{Failure Rate by Requested Resources}
  \label{fig:fail-vs-request}
\end{figure}

In contrast, resource efficiency varies widely, with the majority of tasks underutilizing resources (Figure~\ref{fig:eff-dist}).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/02_distribution_of_resource_efficiency.png}
  \caption{Distribution of Resource Efficiency}
  \label{fig:eff-dist}
\end{figure}

\subsection{Queuing Behavior and Scheduling Fairness}

By dividing tasks into low-queued (Q1--Q3) and high-queued (Q4) groups, we observe that higher queueing levels correlate with:

\begin{itemize}
  \item Higher resource requests (CPU, Memory)
  \item Lower scheduling class (less priority)
  \item \textbf{Lower failure rates}, which is counterintuitive
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\linewidth]{figures/03_queue_level_vs_failure_rate.png}
  \caption{Failure Rate: High vs. Low Queued Tasks}
  \label{fig:queue-vs-fail}
\end{figure}

\subsection{Inefficient Task Characteristics}

To explore extreme inefficiencies, we analyze tasks with \texttt{efficiency < 0.1}. These tasks exhibit either extremely short runtime or maxed-out 300-second durations (Fig.~\ref{fig:ineff-runtime}), often in lower scheduling classes.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\linewidth]{figures/04_distribution_of_runtimes of_inefficient_tasks.png}
  \caption{Runtime Distribution of Inefficient Tasks}
  \label{fig:ineff-runtime}
\end{figure}

\begin{table}[h]
  \centering
  \caption{Top 5 Most Inefficient Tasks}
  \label{tab:top-ineff}
  \begin{tabular}{rrrr}
  \toprule
  Efficiency & Priority & Scheduling Class & Run Time (ns) \\
  \midrule
  0.000063 & 360 & 2 & 3{,}000{,}000 \\
  0.000071 & 360 & 2 & 3{,}000{,}000 \\
  0.000071 & 360 & 2 & 3{,}000{,}000 \\
  0.000128 & 360 & 2 & 1{,}000{,}000 \\
  0.000320 & 105 & 1 & 10{,}000{,}000 \\
  \bottomrule
  \end{tabular}
\end{table}

\subsection{Predicting Task Failures via ML}

We trained Logistic Regression, Random Forest, and XGBoost models using 9000 samples with class-weight balancing. XGBoost achieved the highest AUC (0.998), followed by Random Forest (0.987), and Logistic Regression (0.918).

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\linewidth]{figures/05_roc_curve_comparison.png}
  \caption{ROC Curve Comparison of Three Models}
  \label{fig:roc-comparison}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/05_XGBoost_Feature_Importance.png}
  \caption{Feature Importance in XGBoost Model}
  \label{fig:feature-importance}
\end{figure}

\subsection{Clustering Failed Tasks}

To further investigate the structural patterns of failures, we applied KMeans (k=3) on failed samples, projecting onto priority and runtime dimensions. Results indicate three clusters: short-lived and low-priority, long-running with moderate priority, and scattered outliers.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/05_failed_task_clustering_results.png}
  \caption{KMeans Clustering of Failed Tasks (projected)}
  \label{fig:failed-clustering}
\end{figure}

\section{Conclusion}

In this project, we conducted an in-depth analysis of the Google Borg trace dataset to uncover patterns and risk factors related to task failures and inefficiencies in a large-scale cluster management system. By performing extensive exploratory data analysis (EDA), we observed that failure rates are notably higher among tasks with extremely low resource requests and shorter runtimes, especially within lower scheduling classes.

Our queuing analysis revealed a strong correlation between queuing delay and task priority, indicating fairness issues in resource scheduling. Moreover, we found that inefficient tasks are often either extremely short-lived or long-running but underutilized, and they tend to be distributed across different scheduling categories without clear separation.

We built and evaluated three binary classifiers—Logistic Regression, Random Forest, and XGBoost—for failure prediction. Among them, XGBoost demonstrated the best performance, achieving a ROC-AUC score of 0.998 and identifying \texttt{run\_sec}, \texttt{mem\_request}, and \texttt{scheduling\_class} as the most informative features. Additionally, we applied KMeans clustering to failed tasks, discovering three interpretable failure clusters that may guide future failure handling strategies.

Overall, our study provides both empirical insights and practical tools for understanding workload behavior and improving resource management policies in distributed systems. Future work may involve incorporating temporal trends, performing anomaly detection over time, or designing interpretable predictive frameworks integrated into scheduling systems.

\newpage
% Bibliography (if required)
\bibliographystyle{plain}
\bibliography{references}  % Add a .bib file if you have references

\end{document}
